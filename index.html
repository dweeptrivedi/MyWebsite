<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dweep Trivedi</title>
  
  <meta name="author" content="Dweep Trivedi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon1.png">
</head>
  
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dweep_image.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Dweep Trivedi</name>
              </p>
              <p>I am a visiting researcher at <a href="https://www.clvrai.com/"> Cognitive Learning for Vision and Robotics Lab (CLVR) </a> at <a href= "https://www.cs.usc.edu/">University of Southern California</a>, advised by <a href="https://viterbi-web.usc.edu/~limjj/"> Prof. Joseph Lim </a>.
              </p>
              <p>
                Previously, I finished my Masterâ€™s in Computer Science at <a href="https://www.cs.usc.edu/">University of Southern California</a>, where I worked under the guidance of <a href= "https://sites.google.com/view/skim-home/home" >Dr. Seon Ho Kim</a> and <a href= "https://viterbi-web.usc.edu/~liu32/">Prof. Yan Liu</a>. Earlier, I spent 2 years working as Software Development Engineer in <a href="https://www.juniper.net/us/en.html" >Juniper Networks, Bangalore </a>. I did my undergrad in Information and Communication Technology at <a href="https://www.daiict.ac.in/"> DA-IICT, Gandhinagar</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:dweeptrivedi1994@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/DweepTrivedi_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=Jf9i6GQAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                
                <a href="https://github.com/dweeptrivedi">Github</a>
                <a href="https://twitter.com/dweeptrivedi">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/dweep-trivedi">Linkedin</a> &nbsp/&nbsp
              </p>
            </td>
           
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in Deep Learning, Interpretable Reinforcement Learning, Continual Learning and Robot Learning. 
              </p>
            </td>
          </tr>
        </tbody></table>
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="clipnerf_stop()" onmouseover="clipnerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/paper1_image.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/dweep_image.jpg" class="hoverZoomLink"></a>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://clvrai.github.io/leaps/">
                <papertitle>Learning to Synthesize Programs as Interpretable and Generalizable Policies</papertitle>
              </a>
              <br>
              <strong>Dweep Trivedi</strong>,
              <a href="https://jesbu1.github.io/">Jesse Zhang</a>,
              <a href="https://shaohua0116.github.io/">Shao-Hua Sun</a>,
              <a href="https://viterbi-web.usc.edu/~limjj/">Joseph J Lim</a>,
              
              <br>
        <em>Thirty-Fifth Conference on Neural Information Processing Systems</em>, 2021
              <br>
              <a href="https://papers.nips.cc/paper/2021/file/d37124c4c79f357cb02c655671a432fa-Paper.pdf">PDF</a>
        /
              <a href="https://shaohua0116.github.io/bibtex/leaps.txt">bibTex</a>
       
              <p></p>
              <p>We present a framework that learns to synthesize a program, detailing the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task.</p>
            </td>
          </tr>
        
        </body>

</html>
